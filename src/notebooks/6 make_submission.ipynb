{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Making a Submission</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Specifying a Model and an Output File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIRECTORY = \"models/logistic_regression_f1\"\n",
    "SUBMISSION_PATH = \"submissions/logistic_regression_f1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Making predictions for every feature</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to consider for classification\n",
    "feature_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Predicting for 'toxic' =====\n",
      "===== Predicting for 'severe_toxic' =====\n",
      "===== Predicting for 'obscene' =====\n",
      "===== Predicting for 'threat' =====\n",
      "===== Predicting for 'insult' =====\n",
      "===== Predicting for 'identity_hate' =====\n",
      "Predictions saved to 'submissions/logistic_regression_f1.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "test_data = pd.read_csv('kmaml223/test.csv')\n",
    "test_data['comment_text_cleaned'].fillna('', inplace=True)\n",
    "X_test = test_data['comment_text_cleaned']\n",
    "\n",
    "# Load the saved TfidfVectorizer\n",
    "loaded_tfidf_vectorizer = joblib.load(f\"{MODEL_DIRECTORY}/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Create a dictionary to store predictions\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_data['id']\n",
    "\n",
    "# Iterate through each feature and make predictions\n",
    "for feature in feature_columns:\n",
    "    print(f\"===== Predicting for '{feature}' =====\")\n",
    "    \n",
    "    # Load the stored model for the feature\n",
    "    model_filename = f\"{MODEL_DIRECTORY}/{feature}_model.pkl\"\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    \n",
    "    # Transform test data using the pre-fitted TfidfVectorizer\n",
    "    X_test_tfidf = loaded_tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Add predictions to the submission DataFrame\n",
    "    submission[feature] = predictions\n",
    "\n",
    "# Save predictions to a submission CSV file\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Predictions saved to '{SUBMISSION_PATH}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparing Difference Between Other Submissions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with baseline.csv:\n",
      "Accuracy for 'toxic': 0.9600643971365157\n",
      "Accuracy for 'severe_toxic': 0.9991559598612023\n",
      "Accuracy for 'obscene': 0.9877457876144925\n",
      "Accuracy for 'threat': 0.9986401575541592\n",
      "Accuracy for 'insult': 0.9908093407108693\n",
      "Accuracy for 'identity_hate': 0.9982181374847604\n",
      "\n",
      "Comparison with logistic_regression_accuracy.csv:\n",
      "Accuracy for 'toxic': 0.982118853355841\n",
      "Accuracy for 'severe_toxic': 0.9990309168776768\n",
      "Accuracy for 'obscene': 0.9973115758541998\n",
      "Accuracy for 'threat': 0.999687392541186\n",
      "Accuracy for 'insult': 0.9965769483259871\n",
      "Accuracy for 'identity_hate': 0.9992497420988464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of file paths to compare with the new submission\n",
    "baseline_files = ['baseline.csv', 'logistic_regression_accuracy.csv']  # Add more file paths as needed\n",
    "new_submission = pd.read_csv(SUBMISSION_PATH)\n",
    "\n",
    "for baseline_file in baseline_files:\n",
    "    baseline = pd.read_csv(f\"submissions/{baseline_file}\")\n",
    "    print(f\"Comparison with {baseline_file}:\")\n",
    "    for feature in feature_columns:\n",
    "        accuracy = accuracy_score(baseline[feature], new_submission[feature])\n",
    "        print(f\"Accuracy for '{feature}': {accuracy}\")\n",
    "    print()  # Add a line break between different baseline comparisons\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
